{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import Adam\n",
    "import pandas as pd\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "from GlaucomaDataset import GlaucomaDatasetBoundingBoxes\n",
    "from unet import UNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "origa_path = os.path.join(\"..\", '..', \"data\", \"ORIGA\")\n",
    "images_path = os.path.join(origa_path, \"Images_Square\")\n",
    "masks_path = os.path.join(origa_path, \"Masks_Square\")\n",
    "\n",
    "img_filenames = sorted(os.listdir(images_path))\n",
    "mask_filenames = sorted(os.listdir(masks_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_image_path(path):\n",
    "    split_path = path.split(\"/\")\n",
    "    return split_path[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "bb_df = pd.read_csv(\"../../data/ORIGA/bounding_boxes.csv\")\n",
    "bb_df['image_path'] = bb_df['image_path'].apply(update_image_path)\n",
    "bb_df[['x1', 'y1', 'x2', 'y2']] //= 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into train, validation, and test sets (70, 15, 15)\n",
    "train_imgs, temp_imgs, train_masks, temp_masks = train_test_split(\n",
    "    img_filenames, mask_filenames, test_size=0.3, random_state=42)\n",
    "\n",
    "val_imgs, test_imgs, val_masks, test_masks = train_test_split(\n",
    "    temp_imgs, temp_masks, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "batch_size = 8\n",
    "n_workers = 4\n",
    "\n",
    "train_set = GlaucomaDatasetBoundingBoxes(images_path, masks_path, train_imgs, train_masks, bb_df)\n",
    "val_set = GlaucomaDatasetBoundingBoxes(images_path, masks_path, val_imgs, val_masks, bb_df)\n",
    "test_set = GlaucomaDatasetBoundingBoxes(images_path, masks_path, test_imgs, test_masks, bb_df)\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=batch_size, num_workers=n_workers, shuffle=True)\n",
    "val_loader = DataLoader(val_set, batch_size=batch_size, num_workers=n_workers, shuffle=True)\n",
    "test_loader = DataLoader(test_set, batch_size=batch_size, num_workers=n_workers, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image, image_names, masks, mask_names in test_loader:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 4, 256, 256])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_image_with_bbox(img_array, bbox, color='red', linewidth=2):\n",
    "    \"\"\"\n",
    "    Display an image with a bounding box overlay.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    img_array : numpy.ndarray\n",
    "        Image as a numpy array.\n",
    "    bbox : list or tuple\n",
    "        Bounding box coordinates in the format [x1, y1, x2, y2]\n",
    "        where (x1, y1) is the top-left corner and (x2, y2) is the bottom-right corner.\n",
    "    color : str, default='red'\n",
    "        Color of the bounding box.\n",
    "    linewidth : int, default=2\n",
    "        Width of the bounding box border.\n",
    "    \"\"\"\n",
    "    # Create figure and axes\n",
    "    fig, ax = plt.subplots(1)\n",
    "    \n",
    "    # Display the image\n",
    "    ax.imshow(img_array)\n",
    "    \n",
    "    # Extract coordinates\n",
    "    x1, y1, x2, y2 = bbox\n",
    "    \n",
    "    # Calculate width and height for the rectangle\n",
    "    width = x2 - x1\n",
    "    height = y2 - y1\n",
    "    \n",
    "    # Create a Rectangle patch\n",
    "    rect = patches.Rectangle((x1, y1), width, height, linewidth=linewidth, \n",
    "                             edgecolor=color, facecolor='none')\n",
    "    \n",
    "    # Add the rectangle to the plot\n",
    "    ax.add_patch(rect)\n",
    "    \n",
    "    # Remove axis ticks and labels\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    \n",
    "    # Show the plot\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_coefficient(targets, preds, smooth=1e-6):\n",
    "    # preds = (preds > 0.5).float \n",
    "    intersection = torch.sum(preds * targets, dim=(2,3))\n",
    "    # want close to 1 (identical)\n",
    "    dice = (2. * intersection + smooth) / (torch.sum(preds, dim=(2,3)) + torch.sum(targets, dim=(2,3)) + smooth)\n",
    "    return dice.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and Test Loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainloop(dataloader, model, loss_func, optimizer):\n",
    "    num_batches = len(dataloader)\n",
    "    train_loss, dice = 0., 0. \n",
    "    \n",
    "    for image, image_name, mask, mask_name in dataloader:\n",
    "        image, mask = image.to(device), mask.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        pred = model(image)\n",
    "        loss = loss_func(pred, mask)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "        dice += dice_coefficient(pred, mask).item()\n",
    "    train_loss /= num_batches\n",
    "    dice /= num_batches\n",
    "        \n",
    "    return train_loss, dice\n",
    "\n",
    "def testloop(dataloader, model, loss_func):\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, dice = 0. , 0.\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for image, image_name, mask, mask_name in dataloader:\n",
    "            image, mask = image.to(device), mask.to(device)\n",
    "            pred = model(image)\n",
    "            test_loss += loss_func(pred, mask).item()\n",
    "            dice += dice_coefficient(pred, mask).item()\n",
    "    test_loss /= num_batches\n",
    "    dice /= num_batches\n",
    "    \n",
    "    return test_loss, dice"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "capstone",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
